{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final Loaded Data should be like \n",
    "X: [[ X1, X2,... XN ], ... m] (an m by n matrix. )\n",
    "Where X1 - func\n",
    "X2 - power\n",
    "X3 - mode\n",
    "X4 - temp\n",
    "X5 - swing\n",
    "X6 - fan\n",
    "\n",
    "Y : [[Y1, Y2, Y3...YN2], [Y_2]... [Y_m]] (a m by N2 matrix )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_set_dict = {\n",
    "    \"POWER ON\": 1,\n",
    "    \"POWER OFF\": 2,\n",
    "    \"MODE AUTO\": 3,\n",
    "    \"MODE COOL\": 4,\n",
    "    \"MODE DRY\": 5,\n",
    "    \"MODE FAN\": 6,\n",
    "    \"MODE HEAT\": 7,\n",
    "    \"FAN SPD AUTO\": 8,\n",
    "    'FAN SPD AUTO': 9,\n",
    "    'FAN SPD LOW': 10,\n",
    "    'FAN SPD MID': 11,\n",
    "    'FAN SPD HIGH': 12,\n",
    "    'TEMP UP': 13,\n",
    "    'TEMP DOWN': 14\n",
    "}\n",
    "power_set_dict = {\n",
    "    'ON': 1,\n",
    "    \"OFF\": 2\n",
    "}\n",
    "mode_set_dict = {\n",
    "    'AUTO': 1, 'COOL': 2, 'DRY': 3, 'FAN': 4, 'HEAT': 5\n",
    "}\n",
    "temp_set_dict = {\n",
    "    '16': 1,\n",
    "    '17': 2,\n",
    "    '18': 3,\n",
    "    '19': 4,\n",
    "    '20': 5,\n",
    "    '21': 6,\n",
    "    '22': 7,\n",
    "    '23': 8,\n",
    "    '24': 9,\n",
    "    '25': 10,\n",
    "    '26': 11,\n",
    "    '27': 12,\n",
    "    '28': 13,\n",
    "    '29': 14,\n",
    "    '30': 15,\n",
    "    '31': 16\n",
    "}\n",
    "swing_set_dict = {\n",
    "    'OFF': 1,\n",
    "    'ON' : 2\n",
    "}\n",
    "fan_set_dict = {\n",
    "    'FAN_AUTO': 1, 'FAN_HI': 2, 'FAN_LOW' : 3, 'FAN_MID' : 4\n",
    "}\n",
    "\n",
    "def load_data_set():\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open('data/codeset.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for elem in data[\"keys\"]:\n",
    "            X.append([function_set_dict[elem[\"func\"]], power_set_dict[elem[\"power_set\"]], mode_set_dict[elem[\"mode_set\"]], temp_set_dict[elem[\"temp_set\"]], swing_set_dict[elem[\"swing_set\"]], fan_set_dict[elem[\"fan_set\"]] ])\n",
    "            Y.append(list(map(int, elem[\"code\"].split(',')[:-1])))\n",
    "            \n",
    "    return np.array(X),np.array(Y)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428, 6) (428, 691)\n",
      "(342, 6) (342, 691)\n"
     ]
    }
   ],
   "source": [
    "X,Y = load_data_set()\n",
    "print(X.shape, Y.shape)\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "print(data_train.shape, labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets start creating the model Now\n",
    "- Here i started building the model.\n",
    "- P.S I am very new to this.\n",
    "- Please dont laugh, i just started with some random Numbers and layers configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, input_dim=6))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(691))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "342/342 [==============================] - 0s 166us/sample - loss: 564527.3330 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 0s 92us/sample - loss: 562018.4141 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 0s 80us/sample - loss: 559021.8534 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 0s 74us/sample - loss: 555495.3045 - accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 0s 116us/sample - loss: 551425.2628 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a262b0c18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, labels_train, epochs=5)\n",
    "# And this flopped utterly. It dint train at all. \n",
    "# Acuracy is 0 everytime. \n",
    "# First doubt i have here is this, what should be layer configuration, as in what should be the last layer ? \n",
    "# am i misunderstanding something ?\n",
    "# Does adding a Dense Layer with size N2 in the end makes sense ??\n",
    "# Second doubt i have here is what should i choose for loss here in such kind of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 948us/sample - loss: 549120.5363 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[549120.5363372093, 0.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 691)\n",
      "[20.991146 21.556084 19.449871 24.761446 21.391365 24.037512 21.859682\n",
      " 23.869852 20.29234  22.103645 23.30223  23.503544 22.47481  24.739305\n",
      " 21.279253 23.081892 20.25839  23.056765 24.199446 20.532423 20.404167\n",
      " 24.270212 24.58943  23.482971 18.913837 20.821707 27.534458 18.41457\n",
      " 21.355898 21.688923 20.320244 20.703596 22.935854 25.021881 22.247244\n",
      " 21.96449  23.117601 19.34823  25.40605  25.30695  24.538752 23.318758\n",
      " 23.333193 22.649334 23.460653 19.787165 21.884594 24.8724   23.344265\n",
      " 22.901556 20.758644 22.189    23.455578 22.319593 25.41283  19.7049\n",
      " 20.793968 22.710941 20.464228 24.368881 24.508902 21.987669 25.065247\n",
      " 22.528963 21.067968 21.93486  21.513088 22.589645 18.758217 24.89711\n",
      " 20.382406 21.402166 22.66831  24.52666  22.751558 20.110312 24.18885\n",
      " 24.335842 19.005096 21.720926 21.252651 22.072943 21.884508 25.085419\n",
      " 19.392305 22.62085  20.120543 22.7861   21.33832  21.650282 19.980282\n",
      " 21.373812 21.838772 24.116219 22.959236 21.41128  20.926023 18.889505\n",
      " 24.831818 23.148672 20.462141 28.92231  21.832218 24.395388 20.966528\n",
      " 22.80277  20.213074 20.081633 20.274069 21.335382 24.291384 24.236649\n",
      " 19.30015  22.742805 23.678165 22.752804 26.370363 19.60581  23.429657\n",
      " 22.72311  21.71619  23.070969 21.618374 21.2586   24.717005 23.554968\n",
      " 20.990602 19.349846 25.132664 22.325527 20.411097 22.920727 22.92624\n",
      " 21.570564 23.210016 20.951895 25.28989  18.391632 22.601799 24.917942\n",
      " 21.474257 19.402851 22.324959 21.654531 22.352356 21.33995  23.795149\n",
      " 20.661322 22.649311 22.800148 18.94787  20.814957 20.905046 19.716274\n",
      " 22.876677 21.595499 26.010166 21.4146   20.882324 24.541225 18.087189\n",
      " 20.997482 19.01319  27.199099 23.618547 23.57571  23.026651 23.177118\n",
      " 23.607275 23.03035  21.825432 22.497711 20.37711  22.065144 21.284826\n",
      " 19.788282 23.737932 21.966345 25.578424 20.560844 19.18871  24.947876\n",
      " 20.21151  17.621677 21.789572 24.385252 20.701332 23.798792 22.505434\n",
      " 22.835587 23.694818 23.187792 22.274652 23.163364 25.961212 23.314117\n",
      " 21.021717 19.399408 23.306162 22.02185  21.252615 22.073814 19.91514\n",
      " 22.717794 19.219164 21.443521 25.537197 22.8458   19.192085 15.372568\n",
      " 20.112339 24.50168  22.91001  20.769775 23.203917 17.099848 20.407661\n",
      " 18.91477  23.307291 22.867624 21.108456 24.565887 21.4042   23.817959\n",
      " 24.179403 18.738438 20.446714 22.4378   22.034725 22.358423 21.1941\n",
      " 23.354261 22.498728 20.536201 20.762722 21.370464 23.220003 23.400263\n",
      " 23.713703 22.353897 24.580608 19.465918 20.994793 23.049438 21.658884\n",
      " 22.929853 20.429882 23.696775 25.23052  19.54196  23.786247 25.765047\n",
      " 24.784729 21.383024 21.62767  20.234661 25.747704 21.29606  19.501394\n",
      " 23.675632 22.274384 19.897644 20.942059 22.172136 18.585178 21.27079\n",
      " 23.124842 19.685019 21.024256 22.123745 21.9362   19.990454 22.93437\n",
      " 23.599031 24.312952 18.812279 20.150648 24.53021  21.461645 23.038378\n",
      " 23.575603 21.334982 24.069769 23.476713 20.101301 22.890696 26.37495\n",
      " 22.419962 24.129446 22.984995 24.958538 22.30236  23.632063 19.68721\n",
      " 26.318916 22.961437 19.277092 21.40231  22.686264 24.750935 20.6557\n",
      " 22.817123 20.866085 22.219736 25.3314   20.945328 22.033836 23.273802\n",
      " 23.021255 23.034157 24.286253 21.803604 20.70812  20.40047  19.662241\n",
      " 21.761635 19.592077 21.972502 23.521435 23.832022 23.976755 22.923569\n",
      " 22.404774 24.141933 26.268887 23.752382 21.710054 23.736704 23.462988\n",
      " 24.05566  21.133286 23.079899 20.786747 20.611517 25.726948 22.928402\n",
      " 21.240482 19.35851  22.214834 16.284462 24.751804 23.087284 21.010536\n",
      " 20.12584  22.71697  19.813725 22.300053 21.223639 16.61834  25.92241\n",
      " 21.111494 21.74031  22.206762 23.141378 19.892664 21.387327 21.592657\n",
      " 21.56036  19.882965 23.12304  22.913172 25.521627 19.64718  20.998957\n",
      " 20.475264 24.457306 20.635202 20.570107 19.073366 19.114681 22.978073\n",
      " 23.247137 22.973965 23.766516 25.099865 21.344955 21.018818 24.136744\n",
      " 20.69713  26.182585 23.360548 25.507828 20.828062 23.665924 26.312159\n",
      " 21.45562  24.054096 23.617933 19.316486 24.563086 22.721745 18.461641\n",
      " 21.906992 18.263115 18.335833 22.224245 21.549438 25.759104 22.840948\n",
      " 23.849417 20.560091 21.998692 22.580189 21.969742 18.804539 23.235058\n",
      " 23.11551  26.76252  19.636526 19.290758 23.388672 24.275555 25.291101\n",
      " 21.470957 20.171434 18.78855  20.992418 17.89375  23.697744 21.50659\n",
      " 24.60958  21.635336 22.056957 23.032804 23.683256 18.715855 22.036713\n",
      " 24.825405 21.248781 23.042768 24.183113 18.510033 19.90059  20.019165\n",
      " 19.668312 23.59128  21.519957 19.30309  22.885294 20.445616 19.561089\n",
      " 19.985165 21.320509 24.879635 25.915024 20.588894 21.875652 22.520323\n",
      " 23.013086 22.332981 23.798998 26.400738 25.401258 18.247074 23.991396\n",
      " 25.559196 22.283274 18.898046 21.488598 20.869633 21.855278 25.105091\n",
      " 23.297302 20.278519 20.79855  20.14512  21.455807 19.4951   18.958822\n",
      " 21.696276 25.083147 21.28489  19.873234 21.47613  21.834303 20.501968\n",
      " 22.613104 20.65162  22.559448 22.914173 18.963102 22.613909 22.665758\n",
      " 25.537199 21.274595 25.57711  23.1562   22.817122 21.287699 22.109262\n",
      " 25.476767 20.590431 19.543028 22.88507  19.933498 25.096802 24.548063\n",
      " 24.98443  20.776361 23.602055 21.481676 21.406326 21.52752  24.620388\n",
      " 22.387089 21.034292 21.411219 22.644514 22.353329 21.660934 23.182026\n",
      " 21.980604 21.152086 21.92032  24.188417 22.04209  20.36422  25.66701\n",
      " 22.44197  24.163511 25.06635  20.242973 22.447598 22.310362 23.268087\n",
      " 20.146334 20.002932 25.175638 20.820995 20.011408 19.622282 22.656797\n",
      " 20.75035  19.969746 21.590343 21.206049 18.116262 22.705559 20.783\n",
      " 23.218708 21.21368  23.420439 19.280151 21.46627  24.99585  20.511808\n",
      " 24.139277 22.70756  20.943499 25.052797 26.635683 21.601229 21.816599\n",
      " 18.510498 20.076473 19.54428  22.158716 22.730137 24.447145 23.689882\n",
      " 19.320728 21.030725 21.97216  21.49695  23.080116 25.721169 21.771051\n",
      " 19.75212  23.928621 21.733913 23.76377  21.035656 23.176233 23.81277\n",
      " 21.585274 21.831062 22.55047  21.802538 25.680128 21.940916 21.07062\n",
      " 22.773607 21.53286  27.07998  21.63267  24.489687 23.55856  22.509789\n",
      " 21.814373 23.750374 21.363964 20.837343 23.99563  25.324179 21.724298\n",
      " 19.782696 25.32512  24.07003  23.342499 18.793259 22.465208 24.016897\n",
      " 19.706478 21.284819 23.958391 25.669777 23.812157 21.390722 19.350494\n",
      " 19.928665 23.918037 21.587494 26.021767 21.220318 26.20149  22.037453\n",
      " 22.602434 23.560244 22.537785 26.713512 24.513126 21.71533  20.771517\n",
      " 20.613285 22.334194 20.831167 21.674828 24.33049  21.652395 23.849106\n",
      " 24.738964 18.78935  23.288874 23.777384 21.79505  20.100422 25.045183\n",
      " 22.271666 23.336273 21.883064 17.96752  24.400347 21.332981 21.717537\n",
      " 20.221401 21.499271 23.385826 23.859364 19.573296 22.593554 22.545614\n",
      " 23.811895 25.658642 23.00401  28.962795 23.26648  19.314146 21.31767\n",
      " 19.845572 20.581718 18.787409 22.555305 20.631573 17.499207 21.9829\n",
      " 22.425903 17.297054 21.559383 24.062891 18.846828 23.462658 22.785988\n",
      " 23.375357 19.78774  18.822453 19.99263  22.010702 24.439096 20.20265\n",
      " 25.657381 23.103434 27.465525 21.575459 20.066685 25.233711 22.070444\n",
      " 21.389194 24.424335 23.991354 20.94214  20.451939]\n"
     ]
    }
   ],
   "source": [
    "c = model.predict(data_test)\n",
    "print(c.shape)\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
